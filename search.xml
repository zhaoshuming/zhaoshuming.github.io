<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[OKHttp深入理解]]></title>
    <url>%2F2019%2F02%2F27%2FOKHttp%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[OKHttp请求流程OKHttp的请求流程图如下所示： 如下为使用OKHttp进行Get请求的步骤： //1.新建OKHttpClient客户端 OkHttpClient client = new OkHttpClient(); //新建一个Request对象 Request request = new Request.Builder() .url(url) .build(); //2.Response为OKHttp中的响应 Response response = client.newCall(request).execute(); 首先，我们会在请求的时候初始化一个Call的实例，然后根据同步和异步的不同，分别调用它的 execute() 和 enqueue() 方法，但是它们进行网络访问的逻辑都是一样的，内部最后都会执行到getResponseWithInterceptorChain()方法，这个方法里面通过拦截器组成的责任链，依次经过用户自定义普通拦截器、重试拦截器、桥接拦截器、缓存拦截器、连接拦截器和用户自定义网络拦截器以及访问服务器拦截器等拦截处理过程，来获取到一个响应并交给用户。 分发器Dispatcher使用 OkHttp 的时候，我们会创建一个 RealCall 并将其加入到双端队列中。但是请注意这里的双端队列的名称是 runningSyncCalls，也就是说这种请求是同步请求，会在当前的线程中立即被执行。所以，下面的 getResponseWithInterceptorChain() 就是这个同步的执行过程。而当我们执行完毕的时候，又会调用 Dispatcher 的 finished(RealCall) 方法把该请求从队列中移除。所以，这种同步的请求无法体现分发器的“分发”功能。 除了同步的请求，还有异步类型的请求：当我们拿到了 RealCall 的时候，调用它的 enqueue(Callback responseCallback) 方法并设置一个回调即可。该方法会执行下面这行代码： client.dispatcher().enqueue(new AsyncCall(responseCallback)); 当我们调用了 Dispatcher 的 enqueue(AsyncCall) 方法的时候也会将 AsyncCall 加入到一个队列中，并会在请求执行完毕的时候从该队列中移除，只是这里的队列是 runningAsyncCalls 或者 readyAsyncCalls。它们都是一个双端队列，并用来存储异步类型的请求。它们的区别是，runningAsyncCalls 是正在执行的队列，当正在执行的队列达到了限制的时候，就会将其放置到就绪队列 readyAsyncCalls 中： synchronized void enqueue(AsyncCall call) { if (runningAsyncCalls.size() &lt; maxRequests &amp;&amp; runningCallsForHost(call) &lt; maxRequestsPerHost) { runningAsyncCalls.add(call); executorService().execute(call); } else { readyAsyncCalls.add(call); } } 当把该请求加入到了正在执行的队列之后，我们会立即使用一个线程池来执行该 AsyncCall。这样这个请求的责任链就会在一个线程池当中被异步地执行了。这里的线程池由 executorService() 方法返回： public synchronized ExecutorService executorService() { if (executorService == null) { executorService = new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;(), Util.threadFactory(&quot;OkHttp Dispatcher&quot;, false)); } return executorService; } 显然，当线程池不存在的时候会去创建一个线程池。除了上面的这种方式，我们还可以在构建 OkHttpClient 的时候，自定义一个 Dispacher，并在其构造方法中为其指定一个线程池。 拦截器 在配置 OkHttpClient时设置的interceptors；[eg. 最常用的:日志拦截器] 负责失败重试以及重定向的 RetryAndFollowUpInterceptor；会根据服务器返回的信息判断这个请求是否可以重定向，或者是否有必要进行重试 桥拦截器 BridgeInterceptor 用于从用户的请求中构建网络请求，然后使用该请求访问网络，最后从网络响应当中构建用户响应。[简单的说: 只是用来对请求进行包装，并将服务器响应转换成用户友好的响应] 负责读取缓存直接返回、更新缓存的 CacheInterceptor 负责和服务器建立连接的ConnectInterceptor；这里并没有真正地从网络中获取数据，而仅仅是打开一个连接。在获取连接对象的时候，使用了连接池 ConnectionPool 来复用连接。 public final class ConnectInterceptor implements Interceptor { @Override public Response intercept(Chain chain) throws IOException { RealInterceptorChain realChain = (RealInterceptorChain) chain; Request request = realChain.request(); StreamAllocation streamAllocation = realChain.streamAllocation(); boolean doExtensiveHealthChecks = !request.method().equals(&quot;GET&quot;); HttpCodec httpCodec = streamAllocation.newStream(client, chain, doExtensiveHealthChecks); RealConnection connection = streamAllocation.connection(); return realChain.proceed(request, streamAllocation, httpCodec, connection); } } 这里的HttpCodec 用来编码请求并解码响应，RealConnection 用来向服务器发起连接。它们会在下一个拦截器中被用来从服务器中获取响应信息。 StreamAllocation相当于一个管理类，维护了服务器连接、并发流和请求之间的关系，该类还会初始化一个 Socket 连接对象，获取输入/输出流对象。当我们调用 streamAllocation 的 newStream() 方法的时候，最终会经过一系列的判断到达 StreamAllocation 中的 findConnection() 方法。该方法会被放置在一个循环当中被不停地调用以得到一个可用的连接。它优先使用当前已经存在的连接，不然就使用连接池中存在的连接，再不行的话，就创建一个新的连接。我们使用连接复用的一个好处就是省去了进行 TCP 和 TLS 握手的一个过程。因为建立连接本身也是需要消耗一些时间的，连接被复用之后可以提升我们网络访问的效率。 配置 OkHttpClient 时设置的 networkInterceptors；[for web socket,自行了解] 服务器请求拦截器 CallServerInterceptor 用来向服务器发起请求并获取数据。 位置决定了功能，最后一个 Interceptor 一定是负责和服务器实际通讯的，重定向、缓存等一定是在实际通讯之前的 源码如下： Response getResponseWithInterceptorChain() throws IOException { // Build a full stack of interceptors. List&lt;Interceptor&gt; interceptors = new ArrayList&lt;&gt;(); interceptors.addAll(client.interceptors()); interceptors.add(retryAndFollowUpInterceptor); interceptors.add(new BridgeInterceptor(client.cookieJar())); interceptors.add(new CacheInterceptor(client.internalCache())); interceptors.add(new ConnectInterceptor(client)); if (!forWebSocket) { interceptors.addAll(client.networkInterceptors()); } interceptors.add(new CallServerInterceptor(forWebSocket)); Interceptor.Chain chain = new RealInterceptorChain(interceptors, null, null, null, 0, originalRequest, this, eventListener, client.connectTimeoutMillis(), client.readTimeoutMillis(), client.writeTimeoutMillis()); return chain.proceed(originalRequest); } 这里，我们创建了一个列表对象之后把 client 中的拦截器、重连拦截器、桥拦截器、缓存拦截器、网络连接拦截器和服务器请求拦截器等依次加入到列表中。然后，我们用这个列表创建了一个拦截器链。这里使用了责任链设计模式，每当一个拦截器执行完毕之后会调用下一个拦截器或者不调用并返回结果。显然，我们最终拿到的响应就是这个链条执行之后返回的结果。当我们自定义一个拦截器的时候，也会被加入到这个拦截器链条里。 连接管理：ConnectionPool与请求的缓存类似，OkHttp 的连接池也使用一个双端队列来缓存已经创建的连接： private final Deque&lt;RealConnection&gt; connections = new ArrayDeque&lt;&gt;(); OkHttp 的缓存管理分成两个步骤，一边当我们创建了一个新的连接的时候，我们要把它放进缓存里面；另一边，我们还要来对缓存进行清理。在 ConnectionPool 中，当我们向连接池中缓存一个连接的时候，只要调用双端队列的 add() 方法，将其加入到双端队列即可，而清理连接缓存的操作则交给线程池来定时执行。 在 ConnectionPool 中存在一个静态的线程池： private static final Executor executor = new ThreadPoolExecutor(0 /* corePoolSize */, Integer.MAX_VALUE /* maximumPoolSize */, 60L /* keepAliveTime */, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;(), Util.threadFactory(&quot;OkHttp ConnectionPool&quot;, true)); 每当我们向连接池中插入一个连接的时候就会调用下面的方法，将连接插入到双端队列的同时，会调用上面的线程池来执行清理缓存的任务： void put(RealConnection connection) { assert (Thread.holdsLock(this)); if (!cleanupRunning) { cleanupRunning = true; // 使用线程池执行清理任务 executor.execute(cleanupRunnable); } // 将新建的连接插入到双端队列中 connections.add(connection); } 这里的清理任务是 cleanupRunnable，是一个 Runnable 类型的实例。它会在方法内部调用 cleanup() 方法来清理无效的连接。 在从缓存的连接中取出连接来判断是否应该将其释放的时候使用到了两个变量 maxIdleConnections 和 keepAliveDurationNs，分别表示最大允许的闲置的连接的数量和连接允许存活的最长的时间。默认空闲连接最大数目为5个，keepalive 时间最长为5分钟。该方法会对缓存中的连接进行遍历，以寻找一个闲置时间最长的连接，然后根据该连接的闲置时长和最大允许的连接数量等参数来决定是否应该清理该连接。 Responsebytes()大小有限制，建议用byteStream()。源码如下： public final byte[] bytes() throws IOException { long contentLength = contentLength(); if (contentLength &gt; Integer.MAX_VALUE) { throw new IOException(&quot;Cannot buffer entire body for content length: &quot; + contentLength); } ... } public final InputStream byteStream() { return source().inputStream(); } 缓存使用okhttp的cache，首先需指定缓存路径和大小 private OkHttpClient initClient() { File cacheFile = new File(config.getCacheFilePath()); if (!cacheFile.exists()) { cacheFile.mkdir(); } //缓存大小为30M int cacheSize = 30 * 1024 * 1024; //创建缓存对象 Cache cache = new Cache(getContext(), cacheFile, cacheSize); OkHttpClient.Builder builder = new OkHttpClient.Builder(); builder.addInterceptor(new SercurityKeyInteraptor()) .addInterceptor(new HttpLoggingInterceptor()) .connectTimeout(config.getConnectTimeout(), TimeUnit.SECONDS) .writeTimeout(config.getWriteTimeout(), TimeUnit.SECONDS) .readTimeout(config.getReadTimeout(), TimeUnit.SECONDS) .cache(cache) .cookieJar(new FundCookie()); return mOkHttpClient = builder.build(); } 其次在构造Request时配置缓存策略 CacheControl cc = new CacheControl.Builder() //不使用缓存，但是会保存缓存数据 //.noCache() //不使用缓存，同时也不保存缓存数据 // .noStore() //只使用缓存，（如果我们要加载的数据本身就是本地数据时，可以使用这个，不过目前尚未发现使用场景） //.onlyIfCached() //手机可以接收响应时间小于当前时间加上10s的响应 // .minFresh(10,TimeUnit.SECONDS) //手机可以接收有效期不大于10s的响应 // .maxAge(10,TimeUnit.SECONDS) //手机可以接收超出5s的响应 .maxStale(5,TimeUnit.SECONDS) .build(); Request request = new Request.Builder() .cacheControl(cc) .url(&quot;http://192.168.152.2:8080/cache&quot;).build(); 如果直接使用CacheControl中的常量，则不用调用上面那么多的方法，使用方式如下： Request request = new Request.Builder() //强制使用网络 // .cacheControl(CacheControl.FORCE_NETWORK) //强制使用缓存 .cacheControl(CacheControl.FORCE_CACHE) .url(&quot;http://192.168.152.2:8080/cache&quot;).build(); OkHttp的Cache是根据URL以及请求参数来生成的，并且不支持POST请求。 CacheInterceptor拦截器实现读写操作,读写操作都是通过okio实现,快速,高效流 读: 根据缓存策略实现读取缓存,返回Response,Okhttp中实现的是轻量级 LruCache缓存模式[最近最少使用原则]。然后关于DiskLruCache是如何管理缓存文件的，这个其实也很好理解，首先的原则就是按照LRU这种最近最少使用删除的原则，当总的大小超过限定大小后，删除最近最少使用的缓存文件，它的LRU算法是使用LinkedHashMap进行维护的，这样来保证，保留的缓存文件都是更常使用的。 写: 根据缓存策略,将服务端返回的数据写入磁盘 Okhttp缓存相关的类有如下： CacheControl（HTTP中的Cache-Control和Pragma缓存控制） CacheControl是用于描述HTTP的Cache-Control和Pragma字段的类，用于指定缓存的规则。 CacheStrategy（缓存策略类） CacheStrategy是用于判定使用缓存数据还是网络请求的决策类。 Cache（缓存类） 对外开放的缓存类，提供了缓存的增删改查接口。 InternalCache（内部缓存类） 对内使用的缓存类接口，没有具体实现，只是封装了Cache的使用。 DiskLruCache（文件化的LRU缓存类） 这是真正实现缓存功能的类，将数据存储在文件中，并使用LRU规则（由LinkedHashMap实现），控制对缓存文件的增删改查。 Cookies加载Cookie时,IP地址与域名是有区别的。如果访问的是IP地址,Cookie是不会从publicsuffixes.gz文件中读取Cookie数据。publicsuffixes.gz 就是一个类似apk一样的压缩文件,可以解压通过Txt查看里面的内容。官文提供的原始文件内容: https://publicsuffix.org private class FundCookie implements CookieJar { private final ConcurrentHashMap&lt;String, List&lt;Cookie&gt;&gt; cookieStore = new ConcurrentHashMap&lt;&gt;(); @Override public void saveFromResponse(HttpUrl url, List&lt;Cookie&gt; cookies) { /* * Cookie name 不能重复:需要人为管控 */ cookieStore.put(url.host(), cookies); } @Override public List&lt;Cookie&gt; loadForRequest(HttpUrl url) { /* * 不能用url.host来获取Cookie值,因为在请求过程中可能存在 301 重定向问题,导致重定向的url无法获取Cookie值, * 但它与其它接口属于同一个 domain * 解决办法:将本地所有的Cookie都上传给接口,后台解析会去匹配 KEY-VALUE[SESSION name- Cookie value] * 所以必要保证 不同的domain对应的SESSION name 不能重复 */ List&lt;Cookie&gt; curCookies = new ArrayList&lt;&gt;(); for (List&lt;Cookie&gt; entry : cookieStore.values()) { curCookies.addAll(entry); } return curCookies; } } Gzip http request header中声明Accept-Encoding: gzip，告知服务器客户端接受gzip的数据。 服务器支持的情况下，返回gzip后的response body，同时加入以下header： Content-Encoding: gzip：表明body是gzip过的数据 Content-Length:117：表示body gzip压缩后的数据大小，便于客户端使用。 或 Transfer-Encoding: chunked：分块传输编码 Okhttp 如果header中没有Accept-Encoding，默认自动添加 ，且标记变量transparentGzip为true。 针对返回结果，如果同时满足以下三个条件： transparentGzip为true，即之前自动添加了Accept-Encoding header中标明了Content-Encoding为gzip 有body 移除 Content-Encoding、Content-Length，并对结果进行解压缩。 开发者没有添加Accept-Encoding时，自动添加Accept-Encoding: gzip 自动添加的request，response支持自动解压 手动添加不负责解压缩 自动解压时移除Content-Length，所以上层Java代码想要contentLength时为-1 自动解压时移除 Content-Encoding 自动解压时，如果是分块传输编码，Transfer-Encoding: chunked不受影响。 HttpUrlConnection: 4.4版本之后与okhttp相仿 参考资料https://juejin.im/post/5bc89fbc5188255c713cb8a5#heading-10让 okhttp 支持 post缓存https://jsonchao.github.io/2018/12/01/Android%E4%B8%BB%E6%B5%81%E4%B8%89%E6%96%B9%E5%BA%93%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%80%E3%80%81%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3OKHttp%E6%BA%90%E7%A0%81%EF%BC%89/]]></content>
      <categories>
        <category>HTTP</category>
      </categories>
      <tags>
        <tag>OKHttp</tag>
        <tag>Gzip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[android多线程]]></title>
    <url>%2F2019%2F02%2F27%2Fandroid%E5%A4%9A%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[前言在Android开发中经常会使用到多线程，这里主要是总结Android开发中常见的多线程实现方式，以及这些多线程实现方式的一些特点多线程实现方式主要有： 实现Thread的run()方法或者实现Runable接口 HandlerThread AsyncTask LoaderManager Thread直接使用Thread实现方式，这种方式简单，但不是很优雅。适合数量很少（偶尔一两次）的异步任务，但要处理的异步任务很多的话，使用该方式会导致创建大量的线程，这会影响用户交互。 关键字join、sleep、yield join() method suspends the execution of the calling thread until the object called finishes its execution. 也就是说，t.join()方法阻塞调用此方法的线程(calling thread)，直到线程t完成，此线程再继续；通常用于在main()主线程内，等待其它线程完成再结束main()主线程。 join()方法是让出执行资源（如：CPU时间片），使得其它线程可以获得执行的资源。所以调用join()方法会使进入阻塞状态，该线程被唤醒后会进入runable状态，等待下一个时间片的到来才能再次执行。 sleep()不会让出资源，只是处于睡眠状态（类似只执行空操作）。调用sleep()方法会使进入等待状态，当等待时间到后，如果还在时间片内，则直接进入运行状态，否则进入runable状态，等待下个时间片。 Yield()方法是停止当前线程，让同等优先权的线程运行。如果没有同等优先权的线程，那么Yield()方法将不会起作用。 suspend()可能导致死锁，因此弃用 HandlerThreadHandlerThread，这种方式适合子线程有序的执行异步操作，异步任务的执行一个接着一个。 HandlerThread的内部实现机制很简单，在创建新的线程后，使该线程成为一个Looper线程，让该线程不断的从MessageQueue取出消息并处理。 就应用程序而言，Android系统中JAVA的应用程序和其他系统上相同，都是靠消息驱动来工作的，他们大致的工作原理如下： 1、有一个消息队列，可以往这个消息队列中投递消息。 2、有一个消息循环，不断从消息队列中取出消息，然后处理。 在Android中，一个线程对应一个Looper对象，而一个Looper对象又对应一个MessageQueue（用于存放message）。 循环者Looper类，消息处理类Handler，消息类Message。 Looper对象用来为一个线程开启一个消息循环，用来操作MessgeQueue。默认情况下，Android中新创建的线程是没有开启消息循环的。（主线程除外） 消息处理类（Handler）允许发送和处理Message和Rannable对象到其所在线程的MessageQueue中。（它主要有两个作用：1、将Message或Runnable应用post()方法或sendMessage()方法发送到MessageQueue中，在发送时可以指定延时时间、发送时间或者要携带的bundle数据。当MessageQueue循环到该Message时，调用相应的Handler对象的handlerMessage()方法对其进行处理。2、在子线程中与主线程进行通信，也就是在工作线程中与UI线程进行通信。） 另外，在一个线程中只能有一个Looper和MessageQueue，但是可以有多个Handler,而且这些Handler可以共享一个Looper和MessageQueue。 消息类(Message)被存放在MessageQueue中，一个MessageQueue中可以包含多个Message对象。每个Message对象可以通过Messhe.obtain()方法或者Handler.obtainMessage()方法获得。Message是一个final类，所以不可被继承。 AsyncTaskAsyncTask的内部使用了两个线程池，使用AsyncTask执行异步操作时，会先在SerialExecutor进行一个顺序排队， 后再用ThreadPoolExcutor线程池为你分配一个线程并执行。而整个应用的AsyncTask任务都在排同一条队，有可能等待排队的任务很多，所以一般不会使用AsyncTask执行一些优先级比较高的异步任务。 当然我们是可以跳过不需要进行排队，直接就通过线程池分配一个线程并执行异步任务，但需要注意同时执行太多的异步任务，会影响用户体验，我想Google就是为了限制同时创建太多的线程才会采用一个排队机制的 /** @hide */ public static void setDefaultExecutor(Executor exec) { sDefaultExecutor = exec; } 该方法是隐藏，但可使用反射，设置一个线程池。 AsyncTask， 通常用于耗时的异步处理，且时效性要求不是非常高的那种异步操作。如果时效性要求非常高的操作，不建议使用这个方式，因为AsyncTask的默认实现是有内部排队机制，且是整个应用的AsyncTask的任务进行排队，所以不能保证异步任务能很快的被执行。 LoaderManagerLoaderManager，当请求处理时机需要根据Activity的生命周期进行调整，或需要时刻监测数据的变化，那LoaderManager是很不错的解决方案。 LoaderManager可以解决的问题包括： 1.加载的数据有变化时，会自动通知我们，而不自己监控数据的变化情况，如：用CursorLoader来加载数据库数据，当数据库数据有变化时，可是个展示变化的数据 2.数据的请求处理时机会结合Activity和Fragment的生命周期进行调整，如：若Acivity销毁了，那就不会再去请求新的数据 1.LoaderManager LoaderManager用来负责管理与Activity或者Fragment联系起来的一个或多个Loaders对象. 每个Activity或者Fragment都有唯一的一个LoaderManager实例(通过getLoaderManager()方法获得),用来启动,停止,保持,重启,关闭它的Loaders,这些功能可通过调用initLoader()/restartLoader()/destroyLoader()方法来实现. LoaderManager并不知道数据如何装载以及何时需要装载.相反,它只需要控制它的Loaders们开始,停止,重置他们的Load行为,在配置变换或数据变化时保持loaders们的状态,并使用接口来返回load的结果. 2.Loader Loades负责在一个单独线程中执行查询,监控数据源改变,当探测到改变时将查询到的结果集发送到注册的监听器上.Loader是一个强大的工具,具有如下特点 (1)它封装了实际的数据载入. Activity或Fragment不再需要知道如何载入数据.它们将该任务委托给了Loader,Loader在后台执行查询要求并且将结果返回给Activity或Fragment. (2)客户端不需要知道查询如何执行.Activity或Fragment不需要担心查询如何在独立的线程中执行,Loder会自动执行这些查询操作. (3)它是一种安全的事件驱动方式. Loader检测底层数据,当检测到改变时,自动执行并载入最新数据. 这使得使用Loader变得容易,客户端可以相信Loader将会自己自动更新它的数据. Activity或Fragment所需要做的就是初始化Loader,并且对任何反馈回来的数据进行响应.除此之外,所有其他的事情都由Loader来解决. Loader：该类用于数据的加载 ，类型参数D用于指定Loader加载的数据类型 public class Loader&lt;D&gt; { } 一般我们不直接继承Loader，而是继承AsyncTaskLoader，因为Loader的加载工作并不是在异步线程中。而AsyncTaskLoader实现了异步线程，加载流程在子线程中执行。注意：对该类的调用应该在主线程中完成。 Loader负责数据加载逻辑，LoaderManager负责Loader的调度，开发者只需要自定义自己的Loader，实现数据的加载逻辑，而不再关注数据加载时由于Activity销毁引发的问题。 注意：其实AsyncTaskLoader内部实现异步的方式是使用AsyncTask完成的，上面我们说过AsyncTask的内部是有一个排队机制，但AsyncTaskLoader内部使用AsyncTask进行数据异步加载时，异步任务并不进行排队。而直接由线程池分配新线程来执行。 参考资料https://blog.csdn.net/baidu_36385172/article/details/79705915https://www.cnblogs.com/diysoul/p/5124886.html]]></content>
      <categories>
        <category>android知识点</category>
      </categories>
      <tags>
        <tag>android</tag>
        <tag>thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github博客搭建]]></title>
    <url>%2F2019%2F02%2F20%2Fgithub%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[基本命令hexo clean #/清除静态页面缓存（清除 public 文件夹) hexo g #生成或 hexo generate hexo s #启动本地服务器 或者hexo server,这一步之后就可以通过http://localhost:4000查看了 hexo d #部署到github hexo clean &amp; hexo g &amp; hexo s #一键启动 hexo new page xxx #创建页面命令 文件目录 post source/_post 新建一个文章 draft source/_drafts 新建一个草稿文件 page source 新建一个页面文件 hexo添加分类和标签:--- title: title #文章標題 date: 2016-06-01 23:47:44 #文章生成時間 categories: &quot;Hexo教程&quot; #文章分類目錄 可以省略 tags: #文章標籤 可以省略 - 标签1 - 标签2 description: #你對本頁的描述 可以省略 --- hexo目录结构 markdown编辑器说明：在Hexo中插入图片时，请按照以下步骤进行设置 （1）将站点配置文件中的 post_asset_folde 选项设置成 true （2）在站点文件夹中打开 git bash，输入命令 npm install hexo-asset-image –save 安装插件 （3）此时使用 hexo new title 创建文章时，将同时在 source/_post 文件夹中生成一个与 title 同名的文件夹，我们只需将待添加的图片放进此文件夹中，然后在文章中通过 Markdown 语法进行引用即可例如，在资源文件夹（就是那个与 title 同名的文件夹）中添加了图片 example.PNG，则可以在对应的文章中使用语句 ![示例图片]（title/example.PNG “示例图片”） 添加图片 使用 Hexo Admin 插件（难用）Hexo Admin 是一个本地在线式文章管理器，可以用直观可视化的方式新建、编辑博客文章、page页面，添加标签、分类等，并且支持剪贴板粘贴图片（自动在source_images_目录中创建文件） 在Hexo网站目录下，安装 Hexo Admin 插件 npm install –save hexo-admin 启动本地服务器并打开管理界面，即可使用 hexo server -d open http://localhost:4000/admin/ 参考资料：https://www.cnblogs.com/jackyroc/p/7681938.html https://www.cnblogs.com/fengxiongZz/p/7707219.html https://blog.csdn.net/wsmrzx/article/details/81478945]]></content>
      <categories>
        <category>搭建博客</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F02%2F18%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>搭建博客</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
